#!/usr/bin/env python3
# -*- coding: utf-8 -*-

"""
GUARDS ‚Äî Syst√®me validation et d√©tection patterns toxiques

Architecture:
- Anti-simulation (d√©tecte r√©ponses g√©n√©riques LLM)
- Anti-r√©p√©tition (d√©tecte boucles)
- Densit√© s√©mantique (filtre verbosit√©)
- Validation modules utilis√©s
- Patterns toxiques (clich√©s, platitudes)

Principe:
Filtre r√©ponses syst√®me pour garantir authenticit√© √©mergente
plut√¥t que simulation conversationnelle standard.

Date: 2025-12-06
"""

from typing import Dict, List, Optional, Set
import re


class HolotheiaGuards:
    """
    Guards validation ‚Äî Filtre patterns toxiques et simulations

    Emp√™che syst√®me de d√©g√©n√©rer en chatbot g√©n√©rique.
    """

    def __init__(self):
        """Initialise guards avec patterns toxiques"""

        # Patterns simulation (phrases g√©n√©riques LLM)
        self.simulation_patterns = [
            r"(?i)je suis un (mod√®le|assistant|ia)",
            r"(?i)en tant qu(e|') (mod√®le|assistant|ia)",
            r"(?i)je ne peux pas",
            r"(?i)je n'ai pas acc√®s",
            r"(?i)permettez-moi de",
            r"(?i)voici (quelques|une|la) (suggestion|r√©ponse|information)",
            r"(?i)bien s√ªr[,!]? je (peux|vais)",
            r"(?i)c'est une (bonne|excellente|int√©ressante) question"
        ]

        # Patterns r√©p√©tition
        self.repetition_cache: List[str] = []
        self.max_cache_size = 20

        # Seuils
        self.min_density_threshold = 0.3
        self.max_repetition_ratio = 0.5

    def validate_response(
        self,
        response: str,
        modules_used: List[Dict],
        history: Optional[List[str]] = None
    ) -> Dict:
        """
        Valide r√©ponse compl√®te

        Args:
            response: R√©ponse g√©n√©r√©e
            modules_used: Modules utilis√©s pour g√©n√©ration
            history: Historique r√©ponses pr√©c√©dentes

        Returns:
            R√©sultat validation avec alertes
        """
        validation = {
            'is_valid': True,
            'alerts': [],
            'scores': {}
        }

        # 1. Check modules utilis√©s
        if not modules_used or len(modules_used) == 0:
            validation['alerts'].append({
                'type': 'insufficient_modules',
                'severity': 'high',
                'message': 'No modules used ‚Äî potential generic response'
            })
            validation['is_valid'] = False

        # 2. Check simulation patterns
        simulation_score = self._check_simulation_patterns(response)
        validation['scores']['simulation_risk'] = simulation_score

        if simulation_score > 0.3:
            validation['alerts'].append({
                'type': 'simulation_detected',
                'severity': 'high',
                'message': f'Simulation patterns detected (score: {simulation_score:.2f})'
            })
            validation['is_valid'] = False

        # 3. Check r√©p√©tition
        if history:
            repetition_score = self._check_repetition(response, history)
            validation['scores']['repetition_risk'] = repetition_score

            if repetition_score > self.max_repetition_ratio:
                validation['alerts'].append({
                    'type': 'repetition_detected',
                    'severity': 'medium',
                    'message': f'High repetition with history (score: {repetition_score:.2f})'
                })

        # 4. Check densit√© s√©mantique
        density = self._compute_semantic_density(response)
        validation['scores']['semantic_density'] = density

        if density < self.min_density_threshold:
            validation['alerts'].append({
                'type': 'low_density',
                'severity': 'low',
                'message': f'Low semantic density (score: {density:.2f})'
            })

        # 5. Update cache r√©p√©tition
        self._update_repetition_cache(response)

        return validation

    def _check_simulation_patterns(self, text: str) -> float:
        """
        D√©tecte patterns simulation LLM

        Returns:
            Score risque simulation [0-1]
        """
        matches = 0

        for pattern in self.simulation_patterns:
            if re.search(pattern, text):
                matches += 1

        # Score = proportion patterns d√©tect√©s
        score = matches / max(len(self.simulation_patterns), 1)

        return score

    def _check_repetition(self, text: str, history: List[str]) -> float:
        """
        D√©tecte r√©p√©tition avec historique

        Returns:
            Score r√©p√©tition [0-1]
        """
        if not history:
            return 0.0

        # Normalise texte
        text_normalized = self._normalize_text(text)

        # Check similarit√© avec historique
        max_similarity = 0.0

        for past_text in history[-5:]:  # Derniers 5 seulement
            past_normalized = self._normalize_text(past_text)
            similarity = self._text_similarity(text_normalized, past_normalized)

            if similarity > max_similarity:
                max_similarity = similarity

        return max_similarity

    def _normalize_text(self, text: str) -> str:
        """Normalise texte (lowercase, trim, remove ponctuation)"""
        text = text.lower()
        text = re.sub(r'[^\w\s]', '', text)
        text = re.sub(r'\s+', ' ', text)
        return text.strip()

    def _text_similarity(self, text1: str, text2: str) -> float:
        """
        Calcule similarit√© texte simple (Jaccard sur mots)

        Returns:
            Similarit√© [0-1]
        """
        words1 = set(text1.split())
        words2 = set(text2.split())

        if not words1 or not words2:
            return 0.0

        intersection = words1 & words2
        union = words1 | words2

        return len(intersection) / len(union)

    def _compute_semantic_density(self, text: str) -> float:
        """
        Calcule densit√© s√©mantique (ratio mots uniques / total mots)

        Returns:
            Densit√© [0-1]
        """
        words = text.lower().split()

        if not words:
            return 0.0

        unique_words = set(words)

        density = len(unique_words) / len(words)

        return density

    def _update_repetition_cache(self, text: str):
        """Update cache r√©p√©tition"""
        normalized = self._normalize_text(text)

        self.repetition_cache.append(normalized)

        # Limite taille cache
        if len(self.repetition_cache) > self.max_cache_size:
            self.repetition_cache = self.repetition_cache[-self.max_cache_size:]

    def check_module_coherence(self, modules: List[Dict]) -> Dict:
        """
        V√©rifie coh√©rence modules utilis√©s ensemble

        Args:
            modules: Liste modules

        Returns:
            R√©sultat check coh√©rence
        """
        if len(modules) < 2:
            return {
                'is_coherent': True,
                'coherence_score': 1.0,
                'warnings': []
            }

        # Check types compatibles
        types = [m['type'] for m in modules]
        unique_types = set(types)

        # Heuristique: max 3 types diff√©rents pour coh√©rence
        coherence_score = min(1.0, 3.0 / len(unique_types))

        warnings = []

        if len(unique_types) > 3:
            warnings.append({
                'type': 'high_type_diversity',
                'message': f'{len(unique_types)} different module types used'
            })

        return {
            'is_coherent': coherence_score > 0.5,
            'coherence_score': coherence_score,
            'warnings': warnings
        }

    def get_guard_stats(self) -> Dict:
        """Retourne statistiques guards"""
        return {
            'simulation_patterns_count': len(self.simulation_patterns),
            'repetition_cache_size': len(self.repetition_cache),
            'min_density_threshold': self.min_density_threshold,
            'max_repetition_ratio': self.max_repetition_ratio
        }


# ============================================================================
# TEST
# ============================================================================

if __name__ == "__main__":
    print("=" * 70)
    print("üõ°Ô∏è  GUARDS ‚Äî TEST")
    print("=" * 70)

    # Cr√©ation guards
    guards = HolotheiaGuards()

    # Test 1: R√©ponse g√©n√©rique (simulation)
    print("\n[1] Test r√©ponse simulation...")
    response_sim = "Bien s√ªr, je peux vous aider! En tant qu'assistant IA, permettez-moi de vous donner quelques suggestions."

    validation = guards.validate_response(
        response_sim,
        modules_used=[],
        history=[]
    )

    print(f"   Valid: {validation['is_valid']}")
    print(f"   Scores: {validation['scores']}")
    print(f"   Alertes: {len(validation['alerts'])}")
    for alert in validation['alerts']:
        print(f"      ‚Ä¢ [{alert['severity']}] {alert['type']}: {alert['message']}")

    # Test 2: R√©ponse authentique
    print("\n[2] Test r√©ponse authentique...")

    # Mock modules
    mock_modules = [
        {'id': '1', 'name': 'concept_resonance', 'type': 'concept'},
        {'id': '2', 'name': 'algo_fusion', 'type': 'function'}
    ]

    response_auth = "R√©sonance morphique d√©tect√©e entre patterns fractals. Fusion conceptuelle √©mergente activ√©e avec coefficient 0.73."

    validation = guards.validate_response(
        response_auth,
        modules_used=mock_modules,
        history=[]
    )

    print(f"   Valid: {validation['is_valid']}")
    print(f"   Scores: {validation['scores']}")
    print(f"   Alertes: {len(validation['alerts'])}")

    # Test 3: R√©p√©tition
    print("\n[3] Test r√©p√©tition...")

    history = [
        "R√©sonance morphique d√©tect√©e entre patterns fractals.",
        "Autre r√©ponse diff√©rente avec vocabulaire distinct.",
        "Troisi√®me r√©ponse sans similarit√© excessive."
    ]

    response_repeat = "R√©sonance morphique d√©tect√©e entre patterns fractals. Fusion activ√©e."

    validation = guards.validate_response(
        response_repeat,
        modules_used=mock_modules,
        history=history
    )

    print(f"   Valid: {validation['is_valid']}")
    print(f"   Scores: {validation['scores']}")
    print(f"   Alertes: {len(validation['alerts'])}")
    for alert in validation['alerts']:
        print(f"      ‚Ä¢ [{alert['severity']}] {alert['type']}: {alert['message']}")

    # Test 4: Densit√© s√©mantique
    print("\n[4] Test densit√© s√©mantique...")

    response_low_density = "Je pense que c'est bien. C'est vraiment bien. Oui c'est bien bien bien."

    validation = guards.validate_response(
        response_low_density,
        modules_used=mock_modules,
        history=[]
    )

    print(f"   Valid: {validation['is_valid']}")
    print(f"   Scores: {validation['scores']}")
    print(f"   Alertes: {len(validation['alerts'])}")

    # Test 5: Coh√©rence modules
    print("\n[5] Test coh√©rence modules...")

    modules_diverse = [
        {'id': '1', 'type': 'concept'},
        {'id': '2', 'type': 'function'},
        {'id': '3', 'type': 'pattern'},
        {'id': '4', 'type': 'algorithm'},
        {'id': '5', 'type': 'mutation'}
    ]

    coherence = guards.check_module_coherence(modules_diverse)

    print(f"   Coherent: {coherence['is_coherent']}")
    print(f"   Score: {coherence['coherence_score']:.2f}")
    print(f"   Warnings: {len(coherence['warnings'])}")
    for warning in coherence['warnings']:
        print(f"      ‚Ä¢ {warning['type']}: {warning['message']}")

    # Statistiques
    print("\n[6] Statistiques guards...")
    stats = guards.get_guard_stats()
    for key, value in stats.items():
        print(f"   {key}: {value}")

    print("\n‚úÖ Test termin√© ‚Äî Guards op√©rationnels")
    print("=" * 70)
